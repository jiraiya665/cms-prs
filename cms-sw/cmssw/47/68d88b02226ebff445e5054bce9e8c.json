{"additions": 1177, "auther_ref": "onnxruntime-master", "auther_sha": "a4a87cffcb53a566ec5bb07075878dca6ec79db2", "author": "hqucms", "body": "#### PR description:\r\n\r\nThis PR adds a preliminary ONNXRuntime-based implementation of DeepJet and DeepAK8, following the proposal in https://github.com/cms-sw/cmssw/issues/27458. The runtime of DeepJet (DeepFlavour) b-tagger is reduced by ~7x, while for DeepAK8 the runtime is reduced by a few percent. \r\n\r\nTiming benchmark based on 1000 JetHT Run2017F events (running the standard NanoAOD sequence), measured on a lxplus7 node:\r\n\r\n[before]\r\n```\r\nTimeReport   0.057633     0.057633     0.057633  pfDeepFlavourJetTagsWithDeepInfo\r\nTimeReport   0.003382     0.003382     0.003382  pfDeepBoostedJetTagsAK8WithDeepInfo\r\nTimeReport   0.003456     0.003456     0.003456  pfMassDecorrelatedDeepBoostedJetTagsAK8WithDeepInfo\r\n```\r\n\r\n[after]\r\n```\r\nTimeReport   0.009149     0.009149     0.009149  pfDeepFlavourJetTagsWithDeepInfo\r\nTimeReport   0.003199     0.003199     0.003199  pfDeepBoostedJetTagsAK8WithDeepInfo\r\nTimeReport   0.003124     0.003124     0.003124  pfMassDecorrelatedDeepBoostedJetTagsAK8WithDeepInfo\r\n```\r\n\r\n(Similar speedup is also observed on an AMD CPU.)\r\n\r\nCurrently we set `MLAS_DYNAMIC_CPU_ARCH=0` (introduced in https://github.com/hqucms/onnxruntime/commit/7222aeadaa2731f858e18b555e23e464a6363645) so ONNXRuntime does not attempt to use AVX/AVX2-based kernels even if they are available on the machine. Allowing ONNXRuntime to dynamically switch to AVX/AVX2-based kernels on CPUs supporting these instructions can bring another speed-up of 1.5x ~ 2x, e.g., \r\n\r\n```\r\nMLAS_DYNAMIC_CPU_ARCH=99\r\n\r\nTimeReport   0.005881     0.005881     0.005881  pfDeepFlavourJetTagsWithDeepInfo\r\nTimeReport   0.001769     0.001769     0.001769  pfDeepBoostedJetTagsAK8WithDeepInfo\r\nTimeReport   0.001763     0.001763     0.001763  pfMassDecorrelatedDeepBoostedJetTagsAK8WithDeepInfo\r\n```\r\n\r\n(But then the results are not bitwise reproducible across different CPU architectures).\r\n\r\n#### Overview of the speedups\r\n\r\n<img width=\"690\" alt=\"Screen Shot 2019-10-19 at 14 32 58\" src=\"https://user-images.githubusercontent.com/7973717/67145016-a683cc80-f27d-11e9-9553-b3f78c176a5e.png\">\r\n\r\n(DeepTauID implementation is not included in this PR.)\r\n\r\nMore details in https://indico.cern.ch/event/855787/contributions/3601398/attachments/1929206/3194789/ML_inference_ONNXRuntime_RECOAT_20191018_H_Qu.pdf.\r\n\r\n#### PR Dependencies: \r\n - https://github.com/cms-sw/cmsdist/pull/5259\r\n - https://github.com/cms-data/RecoBTag-Combined/pull/25\r\n\r\n\r\n#### PR validation:\r\n\r\n - Local tests on a large file (~20k events) show changes in the DeepJet/DeepAK8 outputs only at ~ numerical precision level. \r\n - Thread-safety test: compared results from single and 4-, 8-thread runs and obtained consistent results. \r\n - No additional thread pool is created after https://github.com/hqucms/onnxruntime/commit/04f3c766dc4b0cba097ac48af9c8771beb37f3d8: `pstree` shows no additional threads being created during the job run.", "branch": "master", "changed_files": 26, "comments": 49, "commits": 11, "created_at": "1570114506", "deletions": 13, "labels": ["analysis-pending", "code-checks-pending", "comparison-available", "new-package-pending", "orp-pending", "pending-signatures", "reconstruction-pending", "requires-external", "tests-approved", "xpog-pending"], "milestone": "CMSSW_11_0_X", "number": 28112, "release-notes": [], "review_comments": 23, "state": "open", "title": "ONNXRuntime-based implementation of DeepJet, DeepAK8 and DeepDoubleX", "updated_at": "1572428137", "user": "hqucms"}