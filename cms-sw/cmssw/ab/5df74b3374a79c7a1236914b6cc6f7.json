{"additions": 4222, "auther_ref": "dqm-prepare-for-stream-v4", "auther_sha": "b9acc66d21db5212f14581bb80e3b022c8d204b2", "author": "schneiml", "body": "#### PR description:\r\nThis PR depends on many previous PR *and contains them*. Integration will take a while. \r\n\r\nThis PR completely replaces the Core DQM infrastructure. Some things don't change, but are re-implemented. This state was achieved in previous pull requests:\r\n- DQM Histograms are stored and managed by `edm::Service<DQMStore>`.\r\n     - Using a service makes things like online DQM and the DQM@HLT protobuf chain easier, since we can ask the `DQMStore` for a snapshot of the current histograms.\r\n     - Using a service is required to handle job-level products, which we need for multi-run harvesting (and for historical reasons also normal harvesting). \r\n    - Using a service allows legacy modules to work unchanged.\r\n- In non-legacy modules, all dependencies across the the `DQMStore` are passed to edm via `DQMToken` products, that do not contain any data. (As far as possible -- there are no job products, so the job-level dependencies cannot be expressed.)\r\n- There are six supported types of DQM modules:\r\n    - `DQMEDAnalyzer`, based on `edm::one::EDProducer`. Used for the majority of histogram filling in RECO jobs. Soon to be based on `edm::stream`.\r\n    - `DQMOneEDAnalyzer` based on `edm::one::EDProducer`. Used when begin/end job transitions are required. Can accept more `edm::one` specific options. Cannot save per-lumi histograms.\r\n    - `DQMOneLumiEDAnalyzer` based on `edm::one::EDProducer`. Used when begin/end lumi transitions are needed.\r\n    - `DQMGlobalEDAnalyzer` based on `edm::global::EDProducer`. Used for DQM@HLT and a few random other things. Cannot save per-lumi histograms.\r\n    - `DQMEDHarvester` based on `edm::one::EDProducer`. Used in harvesting jobs to manipulate histograms in lumi, run, and job transitions. \r\n    - `edm::EDAnalyzer` legacy modules. Can do filling and harvesting. Not safe to use in the presence of concurrent lumisections. Safe for multi-threaded running from the DQM framework side.\r\n- There are four supported file formats for DQM histograms:\r\n    - DQMIO, `TTree` based ROOT files. Reading and writing implemented in EDM input and output modules in `DQMServices/FwkIO`: `DQMRootSource` and `DQMRootOutputModule`.\r\n    - Legacy `TDirectory` based `DQM_*.root` ROOT files. Only write support, implemented in `DQMServices/Core` (see  #28588). Read support dropped in this PR, unneeded since references where removed. Only this format supports saving JOB histograms.\r\n    - ProtoBuf streamer, a.k.a. `fastHadd` files. Implemented as EDM input and output modules (`DQMFileSaverPB`, `DQMProtobufReader`) in \"streamer\" format for HLT/DAQ.\r\n    - `MEtoEDM` edm based files. Read and written by the Pool I/O modules, after copying `DQMStore` content to edm products using `MEtoEDMConverter`.\r\n\r\nIn this PR, the following features are implemented/modified:\r\n- Mode-less `DQMStore`. While there where many different modes before (`enableMultiThread`, `lsBasedMode`, `forceResetOnLumi`, `collate`, etc.) that could be configured in various ways and changed the behavior of the `DQMStore` (sometimes fundamentally, making certain features only work in certain modes), the new DQMStore has only a single mode. \r\n    - There are two options to control per-lumi saving (`saveByLumi` in the `DQMStore`) and harvesting (`reScope` in `DQMRootSource`). Both can be expressed in terms of _Scope_, see later.\r\n    - Another option, `assertLegacySafe`, only adds assertions to make sure no operations that would be unsafe in the presence of legacy modules sneak in. It does not affect the behaviour.\r\n    - The `verbose` option should not affect the behavior, though it has in the past (if only due to race conditions).\r\n- Data-race free. The new implementation tries very hard to prevent data races even when legacy APIs are used, using fine-grained locking. \r\n    - This does not mean that there are no race conditions. Whenever histograms are read while they are being filled in a multi-threaded context, the results can be dependent on thread interleaving. But, there should be no undefined behavior on C++ level.\r\n    - For safe manipulation of ROOT objects during booking, a callback interface is provided.\r\n    - Currently, there is still only one global `IBooker` and booking methods cannot run concurrently, but it is easy to change this now (will probably be allowed with the `edm::stream` modules).\r\n- _Global_ and _local_ histograms for concurrent lumisections.\r\n    - In the DQM API, we face the conflict that `MonitorElement` objects are held in the modules (so their life cycle has to match that of the module) but also represent histograms whose life cycle depends the data processed (run and lumi transitions). This caused conflicts since the introduction of multi-threading.\r\n    - The new `DQMStore` resolves this conflict by representing each monitor element using (at least) two objects: A _local_ `MonitorElement`, that follows the module life cycle but does not own data, and a _global_ `MonitorElement` that owns histogram data but does not belong to any module. There may be multiple _local_ MEs for one _global_ ME if multiple modules fill the same histogram (`edm::stream` or even independent modules). There may be multiple _global_ MEs for the same histogram if there are concurrent lumisections.\r\n    - The live cycle of _local_ MEs is driven by callbacks from each of the module base classes (`enterLumi`, `leaveLumi`). For legacy `edm::EDAnalyzer`s, global begin/end run/lumi hooks are used, which only work as long as there are no concurrent lumisections.\r\n    - The live cycle of _global_ MEs  is driven by the enter/leave lumi calls (indirectly) and the `cleanupLumi` hook  using the edm feature added in #28562,  #28521 .\r\n    - If there are no concurrent lumisections, both _local_ and _global_ MEs live for the entire job and are always connected in the same way, which means all legacy interactions continue to work. `assertLegacySafe` (enabled by default) checks for this condition and crashes the job if it is violated.\r\n- Harvesting controlled by _Scope_.\r\n    - In the old `DQMStore`, the handling of per-job vs. per-run historgrams as well as the handling of per-lumi histograms in online, offline, and harvesting is very confusing.\r\n- To clarify this situation, we introduce the concept of _Scope_:\r\n    - The _scope_ of a ME can be one of `JOB`, `RUN`, or `LUMI`.\r\n    - The _scope_ defines how long a _global_ ME should be used before it is saved and replaced with a new histogram.\r\n    - The _scope_ must be set during booking.\r\n- By default, the _scope_ for MEs is `RUN`.\r\n    - Code can explicitly use `IBooker::setScope()` to change the scope to e.g. `LUMI`. This replaces the old `setLumiFlag`.\r\n    - When setting `saveByLumi` option in the `DQMStore`, the default scope changes to `LUMI` for all modules that can support per-lumi saving. It could still be manually overridden in code.\r\n    - In harvesting, the default scope is `JOB`. This works for single-run as well as multi-run harvesting, and emulates the old behavior. Moving to scope `RUN` for non-multi-run harvesting would be cleaner, but requires bigger changes to existing code.\r\n- When harvesting, we expect histograms to get merged. This merging can be controlled using a single option in `DQMRootSource`: `reScope`. This option sets the _finest allowed scope_ when reading histograms from the input files.\r\n    - When just merging files (e.g. in the DQMIO merge jobs), `reScope` is set to `LUMI`. The scope of MEs is not changed, histograms are only merged if a run is split over multiple files.\r\n    - When harvesting, `reScope` is set to `RUN`. Now, MEs saved with scope `LUMI` will be switched to scope `RUN` and merged. The harvesting modules can observe increasing statistics in the histogram as a run is processed (like in online DQM).\r\n    - For multi-run harvesting, `reScope` is set to `JOB`. Now, even `RUN` histograms are merged.\r\n- In-order harvesting.\r\n    - Harvesting jobs are always processed sequentially, like the data was taken: runs and lumisections are processed in increasing order. This is implemented in `DQMRootSource`.\r\n\r\n#### PR validation:\r\n\r\nPasses the relevant unit tests and also some `runTheMatrix`workflows. \r\n\r\nKnown broken:\r\n- Online DQM\r\n- ProtoBuf input (only needed online, for DQM@HLT)\r\n- Anything with `DQMStore::load()` (should be unused, but there still is code referring to it, related to references. This can be removed, since references are gone for a while now.)\r\n- Standard Configuration files mostly still work, but need clean up. The DQMStore does not accept many options any more. Esp. check around `DQMRootSource` related to single/multi run harvesting.\r\n- `FastTimerService` and friends might need some changes to get their output written.\r\n- `MEtoEDM` not really tested, but should roughly work as before.\r\n\r\nOther flaws:\r\n- New features (SCOPE, in-order Harvesting, `saveByLumi`) are not tested yet. Even in the new (PR #28612) tests included here.\r\n- Some parts  of the `MonitorElement` implementation can be moved around/removed.", "branch": "master", "changed_files": 547, "comments": 7, "commits": 106, "created_at": "1576244849", "deletions": 46162, "labels": ["alca-pending", "analysis-pending", "code-checks-approved", "comparison-notrun", "core-pending", "dqm-pending", "generators-pending", "hlt-pending", "l1-pending", "new-package-pending", "orp-pending", "pending-signatures", "simulation-pending", "tests-rejected", "upgrade-pending", "xpog-pending"], "milestone": "CMSSW_11_1_X", "number": 28622, "release-notes": [], "review_comments": 2, "state": "open", "title": "DQM: new DQMStore.", "updated_at": "1576255963", "user": "schneiml"}